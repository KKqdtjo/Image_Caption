import json
from collections import Counter
import os

# --- é…ç½®åŒº ---
# å®šä¹‰æˆ‘ä»¬å…³å¿ƒçš„é¢œè‰²å’Œè¡£ç‰©è¯æ±‡
# æ³¨æ„ï¼šæ•°æ®é›†ä¸­çš„tokenså·²ç»æ˜¯å°å†™å½¢å¼
TARGET_COLORS = ['red', 'blue', 'green', 'black', 'white', 'yellow', 'brown', 'pink', 'purple', 'orange', 'gray']
TARGET_CLOTHING = ['shirt', 'jacket', 't-shirt', 'dress', 'hat', 'jeans', 'shorts', 'pants', 'skirt', 'coat', 'suit']
TOP_N = 15  # æ˜¾ç¤ºæœ€é«˜é¢‘çš„å‰Nä¸ªç»“æœ

# --- å‡½æ•°å®šä¹‰ ---
def analyze_captions(json_path):
    """
    åŠ è½½Flickr8Kæ•°æ®é›†çš„JSONæ–‡ä»¶ï¼Œå¹¶å¯¹è®­ç»ƒé›†çš„æè¿°è¿›è¡Œæ·±åº¦åˆ†æã€‚
    """
    print(f"ğŸš€ å¼€å§‹åˆ†ææ•°æ®é›†: {json_path}")

    if not os.path.exists(json_path):
        print(f"âŒ é”™è¯¯: JSONæ–‡ä»¶æœªæ‰¾åˆ° at '{json_path}'")
        return

    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    print("âœ… JSONæ–‡ä»¶åŠ è½½æˆåŠŸï¼")

    # 1. æå–æ‰€æœ‰è®­ç»ƒé›†çš„æè¿° (tokens)
    train_captions_tokens = []
    for image in data['images']:
        if image['split'] == 'train':
            for sentence in image['sentences']:
                train_captions_tokens.append(sentence['tokens'])

    print(f"ğŸ“Š æ‰¾åˆ° {len(train_captions_tokens)} æ¡è®­ç»ƒé›†æè¿°ã€‚")

    # 2. åˆå§‹åŒ–è®¡æ•°å™¨
    all_words_counter = Counter()
    color_counter = Counter()
    clothing_counter = Counter()
    color_clothing_bigram_counter = Counter()

    # 3. éå†æ‰€æœ‰æè¿°è¿›è¡Œç»Ÿè®¡
    for tokens in train_captions_tokens:
        # æ›´æ–°æ€»è¯é¢‘
        all_words_counter.update(tokens)

        # ç”Ÿæˆbigrams (è¯ç»„)
        bigrams = list(zip(tokens[:-1], tokens[1:]))

        # éå†tokensç»Ÿè®¡é¢œè‰²å’Œè¡£ç‰©
        for token in tokens:
            if token in TARGET_COLORS:
                color_counter[token] += 1
            if token in TARGET_CLOTHING:
                clothing_counter[token] += 1
        
        # éå†bigramsç»Ÿè®¡ "é¢œè‰² + è¡£ç‰©" ç»„åˆ
        for bigram in bigrams:
            word1, word2 = bigram
            if word1 in TARGET_COLORS and word2 in TARGET_CLOTHING:
                color_clothing_bigram_counter[f"{word1} {word2}"] += 1

    # 4. æ‰“å°åˆ†ææŠ¥å‘Š
    print("\n" + "="*50)
    print("ğŸ“œ è®­ ç»ƒ é›† æ è¿° åˆ† æ æŠ¥ å‘Š ğŸ“œ")
    print("="*50)

    print(f"\nğŸ¨ é¢œè‰²è¯æ±‡ Top {TOP_N} (åŸºäºé¢„å®šä¹‰åˆ—è¡¨):")
    for color, count in color_counter.most_common(TOP_N):
        print(f"  - {color:<10}: {count} æ¬¡")

    print(f"\nğŸ‘• è¡£ç‰©è¯æ±‡ Top {TOP_N} (åŸºäºé¢„å®šä¹‰åˆ—è¡¨):")
    for clothing, count in clothing_counter.most_common(TOP_N):
        print(f"  - {clothing:<10}: {count} æ¬¡")
        
    print(f"\nğŸ¨ğŸ‘• 'é¢œè‰² + è¡£ç‰©' ç»„åˆ Top {TOP_N}:")
    for combo, count in color_clothing_bigram_counter.most_common(TOP_N):
        print(f"  - {combo:<15}: {count} æ¬¡")

    print(f"\nâ­ æœ€é«˜é¢‘çš„ 'é¢œè‰² + è¡£ç‰©' ç»„åˆæ˜¯: '{color_clothing_bigram_counter.most_common(1)[0][0]}'")

    print("\n" + "="*50)
    print("âœ… åˆ†æå®Œæˆï¼")


# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == '__main__':
    # æ•°æ®é›†JSONæ–‡ä»¶çš„è·¯å¾„
    dataset_json_path = 'flickr8k_aim3/dataset_flickr8k.json'
    analyze_captions(dataset_json_path) 