# 从零搭建图像描述生成模型

## 一、背景介绍

随着互联网技术的发展，文本、图像、语音、视频等多种形式的信息充斥着我们的日常生活。每天我们在接触新信息的同时，也在不断制造出更多新的信息。如何对海量信息进行高效管理成为一个重要的问题。网络上各种媒体社交平台存在大量的图像数据，其中大多数并没有明确的文本标注，这给图像检索和利用带来了较大的挑战。

图像描述任务要求计算机能够生成自然语言的文本来描述图像上的内容。通过图像描述生成模型，可以将图像转化为近似人类语言的描述，就更容易对图像进行相应的检索、分类、理解等工作，也可用于视觉辅助技术中帮助视觉障碍者进行感知。图像描述涉及图像和文本两种模态，因此难点就在于：如何让模型能够正确理解图像的语义信息，学习到图像和文本间的关联，并用自然语言准确描述出来。

本任务要求同学们在给定的训练数据上，自主实现一个图像描述生成模型，并完成模型的训练与预测。最终，将数据处理，模型结构设计，实验结果与分析，经验总结写成一个实验报告文档

## 二、基础知识

目前的图像描述模型结构大多基于编码器-解码器结构，即：将图像输入编码器（Encoder）进行编码得到图像的表征，然后将获得的特征输入文本解码器（Decoder），逐个词语生成图像的描
述。

通常我们采用CNN作为图像编码器，LSTM/Transformer作为文本解码器。关于LSTM/Transformer具体结构细节，可以查看网络上具体的教程和解析，目前已有现成的深度学习框架（Pytorch/Tensorflow）实现了这些模型，可以直接调库，也可以自己编写实现（可以参考网上其他人开源的有注释的代码，加强对模型的理解）。

## 三、模型实现

编码器与解码器的参数是随机初始化的，需要通过模型训练，降低损失，进行参数更新，学到知识。训练就是将图像数据I输入到模型中，通过前向传播（forward），进行预测，得到生成的文本T'。损失通过一个约定好的损失函数f，计算出模型生成的文本T'和人工标注的文本T之间的差距（loss）。参数更新是模型将损失进行梯度回传（backward），更新模型中的参数，使得当前模型不断向最优模型靠近，输出的文本更拟合数据集中标注的图像描述

实际训练时并不是一次把全部数据都输入到模型中，然后更新模型，而是分为多个阶段，每个阶段读入固定数量的数据（batch）。在完成一定数量的训练阶段后，可以在验证集上进行预测，根据损失（或评测指标）的高低，保存当前最优模型。

完成一个图像描述模型的训练和预测，不只需要编写模型部分，还需要进行输入数据处理、训练函数、预测函数、评价函数等功能的实现。希望同学们在实现时养成良好的代码习惯，将函数分开写在不同的python文件中，一般应包括（但不限于）以下几个文件：

- dataset.py：实现数据读入和预处理，batch的组织
- model.py：实现模型的结构
- main.py：实现数据集加载，模型加载，训练函数，预测函数
- eval.py：实现模型的结果评测

## 四、模型评测

获得了模型生成的图像描述文本之后，需要通过一些指标来评测生成的效果。目前图像描述领域主要采用BLEU-1/2/3/4、ROUGE、METEOR、CIDEr来评估图像描述的生成效果。前3个指标也常用于机器翻译任务中，主要反映生成的文本流利度和准确度，CIDEr指标则是专⻔为图像描述任务设计，更关注描述中涉及的图中物体、属性和关系。具体每个指标的计算方式和优缺点可以阅读原文或者网上教程做进一步了解，这里不展开介绍。

目前这些指标的具体计算方法已有开源代码实现，在评测时可以直接调包计算得到结果，可参考：<https://github.com/LuoweiZhou/coco-caption/tree/de6f385503ac9a4305a1dcdc39c02312f9fa13fc>

## 五、任务说明

### 1. 数据集

本次任务要求在公开数据集Flickr8K数据集上进行实验。数据集包含8000张图像，每张图像有5句对应的人工标注的描述，总共40000个图像对。训练集包含30000图文对，用于更新模型参数；验证集包含5000图文对，用于挑选最优模型；测试集包含5000图文对，用于测试和评价模型效果。注意，模型训练过程中只能使用训练集和验证集的数据，不能使用测试集中的数据。

### 2.任务要求

基本要求：实现一个编码器-解码器架构的图像描述生成模型，编码器可采用CNN，解码器可采用LSTM/Transformer，也可以自行选择合适的模型实现。
*进阶挑战：尝试不同的模型结构作为编码器和解码器，对比和分析生成文本的效果。
